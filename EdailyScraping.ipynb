{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EdailyScraping.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlpbokproject/NLP_BOK_Team/blob/master/EdailyScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVbEqmZQZnt",
        "colab_type": "code",
        "outputId": "5c56d771-c64c-4e0f-f676-f62239de059d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_utp7wJvQq5j",
        "colab_type": "text"
      },
      "source": [
        "# 이데일리 기사 크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwefD6u0Q8Lk",
        "colab_type": "text"
      },
      "source": [
        "# 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyswZEiKQbFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup, Comment\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import re\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmMM3C4uE9xw",
        "colab_type": "text"
      },
      "source": [
        "# 크롤링을 원하는 날자 범위 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YRafeE1E7ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime, time\n",
        "\n",
        "#start_date = datetime.datetime(2017,1,1)\n",
        "#end_date = datetime.datetime(2017,12,31)\n",
        "\n",
        "start_date = datetime.datetime.strptime(\"01-03-2017\", \"%d-%m-%Y\") #시작 날짜\n",
        "end_date = datetime.datetime.strptime(\"31-03-2017\", \"%d-%m-%Y\") #종료 날짜\n",
        "\n",
        "date_generated = [start_date + datetime.timedelta(days=x) for x in range(0, (end_date-start_date).days+1)]\n",
        "date_list = []\n",
        "for date in date_generated:\n",
        "    #print(date.strftime(\"%d-%m-%Y\"))\n",
        "    nowdate = str(date.year)+\".\"+str(date.month).zfill(2)+\".\"+str(date.day).zfill(2)\n",
        "    print(nowdate)\n",
        "    date_list.append(\"https://search.naver.com/search.naver?where=news&query=%EA%B8%88%EB%A6%AC&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=\"+nowdate+\"&de=\"+nowdate+\"&docid=&nso=so%3Ar%2Cp%3A%2Ca%3Aall&mynews=0&refresh_start=0&related=0\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkX5eWZTRAwz",
        "colab_type": "text"
      },
      "source": [
        "# 원하는 날짜 범위 내의 '금리'가 들어간 기사(이데일리 기사만) 검색"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVh3CPusQbLD",
        "colab_type": "code",
        "outputId": "6ba7bf52-7a42-42d0-d470-9a0b5fac3679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "tmp =[]\n",
        "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
        "for date in date_list:\n",
        "    driver.get(date)\n",
        "    driver.set_page_load_timeout(30)\n",
        "    driver.find_element_by_xpath(\"\"\"//*[@id=\"news_popup\"]/a\"\"\").click()\n",
        "    time.sleep(1)\n",
        "    driver.find_element_by_xpath(\"\"\"//*[@id=\"ca_1018\"]\"\"\").click()\n",
        "    time.sleep(1)\n",
        "    driver.find_element_by_xpath(\"\"\"//*[@id=\"_nx_option_media\"]/div[2]/div[3]/button[1]/span\"\"\").click()\n",
        "    time.sleep(1)\n",
        "    \n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    a_tags = soup.find_all('a', class_='_sp_each_title')\n",
        "    print(a_tags[0].text)\n",
        "    \n",
        "    tmp.append(a_tags)\n",
        "    \n",
        "    while soup.find('a', class_='next') is not None:\n",
        "        next_click = soup.find('a', class_='next')\n",
        "        url = 'https://search.naver.com/search.naver' + str(next_click['href'])\n",
        "        driver.get(url)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        a_tags = soup.find_all('a', class_='_sp_each_title')\n",
        "        tmp.append(a_tags)\n",
        "        time.sleep(1)\n",
        "        print(a_tags[0].text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chromedriver.exe': 'chromedriver.exe'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0930bf925d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chromedriver.exe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EA%B8%88%EB%A6%AC&nso=so%3Ar%2Cp%3Afrom20170101to20171231%2Ca%3Aall0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_load_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"//*[@id=\"news_popup\"]/a\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CpV_uckRQPt",
        "colab_type": "text"
      },
      "source": [
        "# 각 URL에서의 기사내용 수집(기사제목, URL, 날짜, 본문)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvMoEihyQhAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "date=''\n",
        "prepro=''\n",
        "cnt= 1\n",
        "for j in range(len(tmp)):\n",
        "    for i in tmp[j]:\n",
        "         #제목\n",
        "            print(\"제목 : \" + i.get_text())\n",
        "            title = i.get_text()\n",
        "            #URL\n",
        "            url = str(i['href'])\n",
        "            response = requests.get(url)\n",
        "            soup = BeautifulSoup(response.text,'html.parser')\n",
        "            #print(\"URL : \" + url)\n",
        "            #날짜\n",
        "            if soup.find('div', class_='dates') is not None:\n",
        "                date = soup.find('div', class_='dates').find('p')\n",
        "                date = str(date)\n",
        "                date = date[6:16]\n",
        "                print(date)\n",
        "            #print(\"date : \"+ date)\n",
        "            #본문\n",
        "            if soup.find('div', class_='news_body') is not None:\n",
        "                div_tag = soup.find('div', class_='news_body')\n",
        "                prepro = str(div_tag)\n",
        "                prepro = re.sub('\\n','',prepro,0).strip()\n",
        "                prepro = re.sub('<!--.+?-->','',prepro,0).strip()\n",
        "                prepro = re.sub('<.+?>','',prepro,0).strip()\n",
        "            #print(prepro)\n",
        "            #print('',end='\\n\\n')\n",
        "            new_df = pd.DataFrame({'com':'Edaily','title':title, 'date':date, 'url':url, 'script':prepro}, index=[0])\n",
        "            df1 = pd.concat([df1, new_df])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99RgQQEkRlIM",
        "colab_type": "text"
      },
      "source": [
        "# 수집 데이터 csv파일에 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvrRGXEpRjkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.to_csv(\"./Edaily/edaily_03.csv\", encoding='UTF8')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}